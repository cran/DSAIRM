"QuizID"	"AppID"	"AppTitle"	"TaskID"	"TaskText"	"RecordID"	"Record"	"Type"	"Note"
"DSAIRM_fitconfint"	"fitconfint"	"Confidence Intervals"	1	"Keep all inputs at their default values. Run the simulation. This will perform _nsample = 10_ fits on resampled data for _iter = 20_ iterations each (much too few for any real problem, but we'll keep it low to make things run reasonably quickly). Instead of a single best-fit estimate for the parameters, you now get 10 estimates from which one can compute uncertainty measures such as confidence intervals. You see the lower and upper bounds for a 95% confidence interval reported below the plot. For this example, you should find the best estimate (fitting to the actual data) for the parameter _b_ to be 0.017, while the bounds for this parameter, obtained through repeat-fitting to the bootstrap samples, are 0.011 and 0.018. 


Since bootstrapping involves random sampling, different random number seeds will lead to different results. First, confirm that if you keep the seed the same, the result will be the same by running the simulation again. Then, change the seed to _rngseed = 99_. The point estimate won't change, because it's again the same fit to the data, but the confidence intervals, which involve random sampling of the data, change somewhat. If the speed of your computer allows, increase the number of bootstrap samples (and iterations). Re-run with different random number seeds. As you use more samples, the impact of the random seed setting should diminish and eventually the results should be robust enough that you get essentially the same confidence intervals independent of random number seed.


(As a side note, some optimizers/solvers have a random component. In that case, setting a seed even if not resampling the data is important for reproducibility.)"	"T1R1"	"Upper bound for _b_ with _rngseed_ = 99 (round to 3 digits)."	"Rounded_Numeric"	"Round to two significant digits"
"DSAIRM_fitconfint"	"fitconfint"	"Confidence Intervals"	2	"Fitting parameters in log space vs. linear space does not change the scientific assumptions, but it can sometimes help the optimizer perform faster/better. Let's explore this. 


Reset all inputs, run the simulation. Then, set _parscale = 2_ and repeat. In this case, the results change somewhat. This is maybe not surprising, given that we only take a few steps. In theory, if we ran the solver long enough until it converged (and did enough samples), the results should be the same. However, this does not always happen. Sometimes a solver can get stuck if fitting parameters on one scale but won't get stuck on another scale. This is often the case if a parameter varies over a wide range; in that case fitting in log space is often advantageous. While we can't fully test this (it would take too long), we can explore this a bit. 


Reset all inputs. Then, set iterations to 500, samples to 1 (i.e., we won't do bootstrap, just fitting of the data). You should get an SSR = 2.53. Now, switch to _parscale = 2_ and redo the fit. You should find a somewhat higher SSR. Repeat with 1000 iterations (and if your computer is fast enough, 2000). You should find that the SSR do not change. Thus, the same solver ended up at a different best fit, and the rescaling did in fact not help. You can explore different starting values and see how that impacts results. 


The overall take-home message from this is that sometimes fitting parameter in their natural (linear) scale is best; other times, transforming them, e.g. to a log scale, improves results. Unfortunately, it is hard to know beforehand if transformation helps. Therefore, often trying it both ways is best."	"T2R1"	"SSR for _parscale_ = 2 and 500 iterations (round to 2 digits)."	"Rounded_Numeric"	"Round to two significant digits"
"DSAIRM_fitconfint"	"fitconfint"	"Confidence Intervals"	3	"Expore the app further. The main ideas you should get out of it are that bootstrapping the data is one way you can get confidence intervals (at the cost of longer run times), and that while fitting parameters on different scales does not change the scientific question, it can influence the performance of the optimizer."	"T3R1"	"Nothing"	"None"	""
